<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Client-Side Voice Interview AI</title>

  <style>
    body {
      font-family: system-ui, sans-serif;
      background: #0f172a;
      color: #e5e7eb;
      padding: 20px;
    }
    button {
      padding: 10px 16px;
      border-radius: 6px;
      border: none;
      background: #2563eb;
      color: white;
      cursor: pointer;
      margin-bottom: 10px;
    }
    textarea {
      width: 100%;
      height: 110px;
      background: #020617;
      color: #e5e7eb;
      padding: 12px;
      border-radius: 8px;
      border: 1px solid #334155;
    }
    pre {
      background: #020617;
      padding: 12px;
      border-radius: 8px;
      border: 1px solid #334155;
      white-space: pre-wrap;
      min-height: 80px;
    }
    .metric {
      display: inline-block;
      margin-right: 10px;
      padding: 6px 10px;
      background: #020617;
      border-radius: 6px;
      border: 1px solid #334155;
    }
  </style>
</head>

<body>
  <h2>üéôÔ∏è Client-Side Voice Interview AI</h2>

  <button id="micBtn">üé§ Start Interview</button>

  <textarea id="input" placeholder="Live transcript..."></textarea>

  <h3>üìù Live Summary</h3>
  <pre id="summary">Waiting for speech‚Ä¶</pre>

  <div>
    <span class="metric" id="status">Status: loading</span>
    <span class="metric" id="latency">Inference: -- ms</span>
  </div>

  <script>
    // ===============================
    // WORKER
    // ===============================
    const worker = new Worker("./worker.js");

    const micBtn = document.getElementById("micBtn");
    const input = document.getElementById("input");
    const summaryEl = document.getElementById("summary");
    const statusEl = document.getElementById("status");
    const latencyEl = document.getElementById("latency");

    function speak(text) {
      if (!text) return;
      speechSynthesis.cancel();
      speechSynthesis.speak(new SpeechSynthesisUtterance(text));
    }

    worker.onmessage = e => {
      if (e.data.type === "ready") {
        statusEl.innerText =
          `Status: ready | Model load: ${e.data.loadTime.toFixed(1)} ms`;
      }

      if (e.data.type === "result") {
        summaryEl.innerText = e.data.summary;
        latencyEl.innerText =
          `Inference: ${e.data.latency.toFixed(1)} ms`;

        if (e.data.filler) {
          speak(e.data.filler);
        }
      }
    };

    // ===============================
    // SPEECH RECOGNITION
    // ===============================
    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;

    let recognition;
    let listening = false;
    let silenceTimer = null;
    let lastTranscript = "";

    const SILENCE_MS = 1200;

    if (SpeechRecognition) {
      recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = "en-US";
    }

    micBtn.onclick = () => {
      if (!recognition) {
        alert("Speech Recognition not supported. Use Chrome or Edge.");
        return;
      }

      if (!listening) {
        recognition.start();
        micBtn.innerText = "üõë Stop Interview";
        listening = true;
      } else {
        recognition.stop();
        micBtn.innerText = "üé§ Start Interview";
        listening = false;
      }
    };

    recognition.onresult = e => {
      const lastResult = e.results[e.results.length - 1];
      if (!lastResult.isFinal) return;

      const text = lastResult[0].transcript.trim();
      if (!text) return;

      lastTranscript = text;
      input.value = text;

      clearTimeout(silenceTimer);

      silenceTimer = setTimeout(() => {
        worker.postMessage({
          text: lastTranscript,
          pause: true
        });

        lastTranscript = "";
        input.value = "";
      }, SILENCE_MS);
    };
  </script>
</body>
</html>
